@article{Shu2018FakeNewsNetAD,
    title={FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media},
    author={Kai Shu and Deepak Mahudeswaran and Suhang Wang and Dongwon Lee and Huan Liu},
    journal={ArXiv},
    pages = {22--36},
    year={2018},
    volume={abs/1809.01286}
}
@article{Shu:2017:FND:3137597.3137600,
    author = {Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan},
    title = {Fake News Detection on Social Media: A Data Mining Perspective},
    journal = {SIGKDD Explor. Newsl.},
    issue_date = {June 2017},
    volume = {19},
    number = {1},
    month = sep,
    year = {2017},
    issn = {1931-0145},
    pages = {22--36},
    numpages = {15},
    url = {http://doi.acm.org/10.1145/3137597.3137600},
    doi = {10.1145/3137597.3137600},
    acmid = {3137600},
    publisher = {ACM},
    address = {New York, NY, USA},
}
@article{shu2017exploiting,
    title={Exploiting Tri-Relationship for Fake News Detection},
    author={Shu, Kai and Wang, Suhang and Liu, Huan},
    journal={arXiv preprint arXiv:1712.07709},
    year={2017}
}
@article{10.1257/jep.31.2.211,
    Author = {Allcott, Hunt and Gentzkow, Matthew},
    Title = {Social Media and Fake News in the 2016 Election},
    Journal = {Journal of Economic Perspectives},
    Volume = {31},
    Number = {2},
    Year = {2017},
    Month = {May},
    Pages = {211-36},
    DOI = {10.1257/jep.31.2.211},
    URL = {http://www.aeaweb.org/articles?id=10.1257/jep.31.2.211}
}
@misc{vaikmaa_2019,
    title={Manipulation And Disinformation In Social Media: The Case Of Estonia And \#ESTexitEU},
    howpublished={\url{https://euvsdisinfo.eu/manipulation-and-disinformation-in-social-media-the-case-of-estonia-and-estexiteu/}},
    journal={EU vs DISINFORMATION},
    author={Vaikmaa, Madis},
    year={2019},
    month={4}
}
@misc{agencies_2016,
    title={Washington gunman motivated by fake news 'Pizzagate' conspiracy},
    howpublished={\url{https://www.theguardian.com/us-news/2016/dec/05/gunman-detained-at-comet-pizza-restaurant-was-self-investigating-fake-news-reports}},
    journal={The Guardian},
    publisher={Guardian News and Media},
    author={Guardian staff and agencies},
    year={2016},
    month={12}
}
@inproceedings{Guo:2018:RDH:3269206.3271709,
    author = {Guo, Han and Cao, Juan and Zhang, Yazi and Guo, Junbo and Li, Jintao},
    title = {Rumor Detection with Hierarchical Social Attention Network},
    booktitle = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
    series = {CIKM '18},
    year = {2018},
    isbn = {978-1-4503-6014-2},
    location = {Torino, Italy},
    pages = {943--951},
    numpages = {9},
    url = {http://doi.acm.org/10.1145/3269206.3271709},
    doi = {10.1145/3269206.3271709},
    acmid = {3271709},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {attention mechanism, recurrent neural network, rumor detection},
}
@inproceedings{Khattar:2019:MMV:3308558.3313552,
    author = {Khattar, Dhruv and Goud, Jaipal Singh and Gupta, Manish and Varma, Vasudeva},
    title = {MVAE: Multimodal Variational Autoencoder for Fake News Detection},
    booktitle = {The World Wide Web Conference},
    series = {WWW '19},
    year = {2019},
    isbn = {978-1-4503-6674-8},
    location = {San Francisco, CA, USA},
    pages = {2915--2921},
    numpages = {7},
    url = {http://doi.acm.org/10.1145/3308558.3313552},
    doi = {10.1145/3308558.3313552},
    acmid = {3313552},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {Fake news detection, microblogs, multimodal fusion, variational autoencoders},
}
@INPROCEEDINGS{7023340,
    author={Z. {Jin} and J. {Cao} and Y. {Jiang} and Y. {Zhang}},
    booktitle={2014 IEEE International Conference on Data Mining},
    title={News Credibility Evaluation on Microblog with a Hierarchical Propagation Model},
    year={2014},
    volume={},
    number={},
    pages={230-239},
    keywords={information analysis;iterative methods;optimisation;social networking (online);news credibility evaluation;microblog;hierarchical propagation model;news communication media;social network;three-layer credibility network;graph optimization problem;iterative algorithm;Optimization;Clustering algorithms;Vectors;Semantics;Feature extraction;Symmetric matrices;Media;Social media credibility;Microblog;news credibility;rumor detection},
    doi={10.1109/ICDM.2014.91},
    ISSN={1550-4786},
    month={12}
}
@article{shen2017discovering,
    title={Discovering social spammers from multiple views},
    author={Shen, Hua and Ma, Fenglong and Zhang, Xianchao and Zong, Linlin and Liu, Xinyue and Liang, Wenxin},
    journal={Neurocomputing},
    volume={225},
    pages={49--57},
    year={2017},
    publisher={Elsevier}
}
@inproceedings{Huang:2017:DFO:3041021.3054233,
    author = {Huang, Hen-Hsen and Wen, Yu-Wei and Chen, Hsin-Hsi},
    title = {Detection of False Online Advertisements with DCNN},
    booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
    series = {WWW '17 Companion},
    year = {2017},
    isbn = {978-1-4503-4914-7},
    location = {Perth, Australia},
    pages = {795--796},
    numpages = {2},
    url = {https://doi.org/10.1145/3041021.3054233},
    doi = {10.1145/3041021.3054233},
    acmid = {3054233},
    publisher = {International World Wide Web Conferences Steering Committee},
    address = {Republic and Canton of Geneva, Switzerland},
    keywords = {convolutional neural network, opinion spam detection, overstated advertisement identification},
}
@inproceedings{Ruchansky:2017:CHD:3132847.3132877,
    author = {Ruchansky, Natali and Seo, Sungyong and Liu, Yan},
    title = {CSI: A Hybrid Deep Model for Fake News Detection},
    booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
    series = {CIKM '17},
    year = {2017},
    isbn = {978-1-4503-4918-5},
    location = {Singapore, Singapore},
    pages = {797--806},
    numpages = {10},
    url = {http://doi.acm.org/10.1145/3132847.3132877},
    doi = {10.1145/3132847.3132877},
    acmid = {3132877},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {deep learning, fake news detection, group anomaly detection, neural network, social networks, temporal analysis},
}
@inproceedings{Wang:2018:EEA:3219819.3219903,
    author = {Wang, Yaqing and Ma, Fenglong and Jin, Zhiwei and Yuan, Ye and Xun, Guangxu and Jha, Kishlay and Su, Lu and Gao, Jing},
    title = {EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection},
    booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&\#38; Data Mining},
    series = {KDD '18},
    year = {2018},
    isbn = {978-1-4503-5552-0},
    location = {London, United Kingdom},
    pages = {849--857},
    numpages = {9},
    url = {http://doi.acm.org/10.1145/3219819.3219903},
    doi = {10.1145/3219819.3219903},
    acmid = {3219903},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {adversarial neural networks, deep learning, fake news detection},
}
@inproceedings{potthast-etal-2018-stylometric,
    title = "A Stylometric Inquiry into Hyperpartisan and Fake News",
    author = "Potthast, Martin  and
      Kiesel, Johannes  and
      Reinartz, Kevin  and
      Bevendorff, Janek  and
      Stein, Benno",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1022",
    doi = "10.18653/v1/P18-1022",
    pages = "231--240",
    abstract = "We report on a comparative style analysis of hyperpartisan (extremely one-sided) news and fake news. A corpus of 1,627 articles from 9 political publishers, three each from the mainstream, the hyperpartisan left, and the hyperpartisan right, have been fact-checked by professional journalists at BuzzFeed: 97{\%} of the 299 fake news articles identified are also hyperpartisan. We show how a style analysis can distinguish hyperpartisan news from the mainstream (F1 = 0.78), and satire from both (F1 = 0.81). But stylometry is no silver bullet as style-based fake news detection does not work (F1 = 0.46). We further reveal that left-wing and right-wing news share significantly more stylistic similarities than either does with the mainstream. This result is robust: it has been confirmed by three different modeling approaches, one of which employs Unmasking in a novel way. Applications of our results include partisanship detection and pre-screening for semi-automatic fake news detection.",
}
@article{DBLP:journals/corr/abs-1903-01728,
    author    = {Chuan Guo and
            Juan Cao and
            Xueyao Zhang and
            Kai Shu and
            Miao Yu},
    title     = {Exploiting Emotions for Fake News Detection on Social Media},
    journal   = {CoRR},
    volume    = {abs/1903.01728},
    year      = {2019},
    url       = {http://arxiv.org/abs/1903.01728},
    archivePrefix = {arXiv},
    eprint    = {1903.01728},
    pages = {1--9},
    timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
    biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-01728},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{wang-2017-liar,
    title = {{``}Liar, Liar Pants on Fire{''}: A New Benchmark Dataset for Fake News Detection},
    author = {Wang, William Yang},
    booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
    month = jul,
    year = {2017},
    address = {Vancouver, Canada},
    publisher = {Association for Computational Linguistics},
    url = {https://www.aclweb.org/anthology/P17-2067},
    doi = {10.18653/v1/P17-2067},
    pages = {422--426},
}
@inproceedings{karimi-tang-2019-learning,
    title = {Learning Hierarchical Discourse-level Structure for Fake News Detection},
    author = {Karimi, Hamid  and
            Tang, Jiliang},
    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
    month = jun,
    year = {2019},
    address = {Minneapolis, Minnesota},
    publisher = {Association for Computational Linguistics},
    url = {https://www.aclweb.org/anthology/N19-1347},
    pages = {3432--3442},
}
@inproceedings{karimi-etal-2018-multi,
    title = "Multi-Source Multi-Class Fake News Detection",
    author = "Karimi, Hamid  and
    Roy, Proteek  and
    Saba-Sadiya, Sari  and
    Tang, Jiliang",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C18-1131",
    pages = "1546--1557",
    abstract = "Fake news spreading through media outlets poses a real threat to the trustworthiness of information and detecting fake news has attracted increasing attention in recent years. Fake news is typically written intentionally to mislead readers, which determines that fake news detection merely based on news content is tremendously challenging. Meanwhile, fake news could contain true evidence to mock true news and presents different degrees of fakeness, which further exacerbates the detection difficulty. On the other hand, the spread of fake news produces various types of data from different perspectives. These multiple sources provide rich contextual information about fake news and offer unprecedented opportunities for advanced fake news detection. In this paper, we study fake news detection with different degrees of fakeness by integrating multiple sources. In particular, we introduce approaches to combine information from multiple sources and to discriminate between different degrees of fakeness, and propose a Multi-source Multi-class Fake news Detection framework MMFD, which combines automated feature extraction, multi-source fusion and automated degrees of fakeness detection into a coherent and interpretable model. Experimental results on the real-world data demonstrate the effectiveness of the proposed framework and extensive experiments are further conducted to understand the working of the proposed framework.",
}
@article{Yang_Shu_Wang_Gu_Wu_Liu_2019, 
    title={Unsupervised Fake News Detection on Social Media: A Generative Approach},
    volume={33}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/4508}, 
    DOI={10.1609/aaai.v33i01.33015644}, 
    abstractNote={&lt;p&gt;Social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. However, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. Therefore, detecting fake news has become a crucial problem attracting tremendous research effort. Most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. In search of an alternative, in this paper, we investigate if we could detect fake news in an &lt;em&gt;unsupervised&lt;/em&gt; manner. We treat truths of news and users’ credibility as latent random variables, and exploit users’ engagements on social media to identify their opinions towards the authenticity of news. We leverage a Bayesian network model to capture the conditional dependencies among the truths of news, the users’ opinions, and the users’ credibility. To solve the inference problem, we propose an efficient collapsed Gibbs sampling approach to infer the truths of news and the users’ credibility without any labelled data. Experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.&lt;/p&gt;}, 
    number={01}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Yang, Shuo and Shu, Kai and Wang, Suhang and Gu, Renjie and Wu, Fan and Liu, Huan}, 
    year={2019}, 
    month={Jul.}, 
    pages={5644-5651} 
}
@inproceedings{Castillo:2011:ICT:1963405.1963500,
    author = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
    title = {Information Credibility on Twitter},
    booktitle = {Proceedings of the 20th International Conference on World Wide Web},
    series = {WWW '11},
    year = {2011},
    isbn = {978-1-4503-0632-4},
    location = {Hyderabad, India},
    pages = {675--684},
    numpages = {10},
    url = {http://doi.acm.org/10.1145/1963405.1963500},
    doi = {10.1145/1963405.1963500},
    acmid = {1963500},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {social media analytics, social media credibility, twitter},
}
@INPROCEEDINGS{8397048,
    author={K. {Shu} and S. {Wang} and H. {Liu}},
    booktitle={2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)},
    title={Understanding User Profiles on Social Media for Fake News Detection},
    year={2018},
    volume={},
    number={},
    pages={430-435},
    keywords={social networking (online);incorporate user social engagements;user profiles;social media;fake news items;future automatic fake news detection research;traditional news outlets;Social network services;Feature extraction;Linguistics;Correlation;Ecosystems;Visualization;Metadata;Fake News;User Profile;Trust Analysis},
    doi={10.1109/MIPR.2018.00092},
    ISSN={},
    month={4},
}
@article{DBLP:journals/corr/abs-1904-13355,
    author    = {Kai Shu and
            Xinyi Zhou and
            Suhang Wang and
            Reza Zafarani and
            Huan Liu},
    title     = {The Role of User Profile for Fake News Detection},
    journal   = {CoRR},
    volume    = {abs/1904.13355},
    year      = {2019},
    url       = {http://arxiv.org/abs/1904.13355},
    archivePrefix = {arXiv},
    eprint    = {1904.13355},
    pages={1-8},
    timestamp = {Thu, 02 May 2019 15:13:44 +0200},
    biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-13355},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Tacchini2017SomeLI,
    title={Some Like it Hoax: Automated Fake News Detection in Social Networks},
    author={Eugenio Tacchini and Gabriele Ballarin and Marco L. Della Vedova and Stefano Moret and Luca de Alfaro},
    journal={ArXiv},
    year={2017},
    pages={1-12},
    volume={abs/1704.07506}
}
@inproceedings{Jin:2016:NVE:3016100.3016318,
    author = {Jin, Zhiwei and Cao, Juan and Zhang, Yongdong and Luo, Jiebo},
    title = {News Verification by Exploiting Conflicting Social Viewpoints in Microblogs},
    booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
    series = {AAAI'16},
    year = {2016},
    location = {Phoenix, Arizona},
    pages = {2972--2978},
    numpages = {7},
    url = {http://dl.acm.org/citation.cfm?id=3016100.3016318},
    acmid = {3016318},
    publisher = {AAAI Press},
}
@inproceedings{Wu:2018:TFF:3159652.3159677,
    author = {Wu, Liang and Liu, Huan},
    title = {Tracing Fake-News Footprints: Characterizing Social Media Messages by How They Propagate},
    booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
    series = {WSDM '18},
    year = {2018},
    isbn = {978-1-4503-5581-0},
    location = {Marina Del Rey, CA, USA},
    pages = {637--645},
    numpages = {9},
    url = {http://doi.acm.org/10.1145/3159652.3159677},
    doi = {10.1145/3159652.3159677},
    acmid = {3159677},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {classification, fake news detection, graph mining, misinformation, social media mining, social network analysis},
}
@article{DBLP:journals/corr/abs-1902-06673,
    author    = {Federico Monti and
            Fabrizio Frasca and
            Davide Eynard and
            Damon Mannion and
            Michael M. Bronstein},
    title     = {Fake News Detection on Social Media using Geometric Deep Learning},
    journal   = {CoRR},
    volume    = {abs/1902.06673},
    year      = {2019},
    url       = {http://arxiv.org/abs/1902.06673},
    archivePrefix = {arXiv},
    eprint    = {1902.06673},
    pages = {1--15},
    timestamp = {Tue, 21 May 2019 18:03:39 +0200},
    biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-06673},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ijcai2018-533,
    title     = {Neural User Response Generator: Fake News Detection with Collective User Intelligence},
    author    = {Feng Qian and Chengyue Gong and Karishma Sharma and Yan Liu},
    booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
            Artificial Intelligence, {IJCAI-18}},
    publisher = {International Joint Conferences on Artificial Intelligence Organization},
    pages     = {3834--3840},
    year      = {2018},
    month     = {7},
    doi       = {10.24963/ijcai.2018/533},
    url       = {https://doi.org/10.24963/ijcai.2018/533},
}
@inproceedings{Yu:2017:SSG:3298483.3298649,
    author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
    title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
    booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
    series = {AAAI'17},
    year = {2017},
    location = {San Francisco, California, USA},
    pages = {2852--2858},
    numpages = {7},
    url = {http://dl.acm.org/citation.cfm?id=3298483.3298649},
    acmid = {3298649},
    publisher = {AAAI Press},
}
@article{ZAROCOSTAS2020676,
title = {How to fight an infodemic},
journal = {The Lancet},
volume = {395},
number = {10225},
pages = {676},
year = {2020},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(20)30461-X},
author = {John Zarocostas}
}
@article{DBLP:journals/corr/abs-1905-12616,
  author    = {Rowan Zellers and
               Ari Holtzman and
               Hannah Rashkin and
               Yonatan Bisk and
               Ali Farhadi and
               Franziska Roesner and
               Yejin Choi},
  title     = {Defending Against Neural Fake News},
  journal   = {CoRR},
  volume    = {abs/1905.12616},
  pages = {1–21},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12616},
  archivePrefix = {arXiv},
  eprint    = {1905.12616},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-12616.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{gillin_2017,
title={PolitiFact - Fake news story about Trump banning Facebook by executive order is an April Fool's Day prank},
howpublished={\url{https://www.politifact.com/factchecks/2017/apr/27/blog-posting/fake-news-story-about-trump-banning-facebook-execu/}},
journal={politifact},
author={Gillin, Joshua},
year={2017},
month={Apr},
note={visited on 2021-01-26}
}
@misc{Radford_GPT2,
  added-at = {2019-02-27T03:35:25.000+0100},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  biburl = {https://www.bibsonomy.org/bibtex/2b30710316a8cfbae687672ea1f85c193/kirk86},
  description = {Language Models are Unsupervised Multitask Learners},
  interhash = {ce8168300081d74707849ed488e2a458},
  intrahash = {b30710316a8cfbae687672ea1f85c193},
  keywords = {learning multitask},
  timestamp = {2019-02-27T03:35:25.000+0100},
  pages = {1–24},
  title = {Language Models are Unsupervised Multitask Learners},
  url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf},
  year = 2018
}
@inproceedings{bird-loper-2004-nltk,
    title = "{NLTK}: The Natural Language Toolkit",
    author = "Bird, Steven  and
      Loper, Edward",
    booktitle = "Proceedings of the {ACL} Interactive Poster and Demonstration Sessions",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P04-3031",
    pages = "214--217",
}
@article{10.5555/944919.944966,
author = {Bengio, Yoshua and Ducharme, R\'{e}jean and Vincent, Pascal and Janvin, Christian},
title = {A Neural Probabilistic Language Model},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {1137–1155},
numpages = {19}
}
@misc{hern_2020, 
title={5G conspiracy theories fuel attacks on telecoms workers}, 
howpublished={\url{https://www.theguardian.com/business/2020/may/07/5g-conspiracy-theories-attacks-telecoms-covid}}, 
journal={The Guardian}, 
publisher={Guardian News and Media}, 
author={Hern, Alex}, 
year={2020}, 
month={May},
note={visited on 2021-01-26}
}
@misc{waterson_hern_2020, 
title={At least 20 UK phone masts vandalised over false 5G coronavirus claims}, 
howpublished={\url{https://www.theguardian.com/technology/2020/apr/06/at-least-20-uk-phone-masts-vandalised-over-false-5g-coronavirus-claims}}, 
journal={The Guardian}, 
publisher={Guardian News and Media}, 
author={Waterson, Jim and Hern, Alex}, 
year={2020}, 
month={Apr},
note={visited on 2021-01-26}
}
@article{10.1145/3386253,
author = {Liu, Yang and Wu, Yi-Fang Brook},
title = {FNED: A Deep Network for Fake News Early Detection on Social Media},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3386253},
doi = {10.1145/3386253},
abstract = {The fast spreading of fake news stories on social media can cause inestimable social harm. Developing effective methods to detect them early is of paramount importance. A major challenge of fake news early detection is fully utilizing the limited data observed at the early stage of news propagation and then learning useful patterns from it for identifying fake news. In this article, we propose a novel deep neural network to detect fake news early. It has three novel components: (1) a status-sensitive crowd response feature extractor that extracts both text features and user features from combinations of users’ text response and their corresponding user profiles, (2) a position-aware attention mechanism that highlights important user responses at specific ranking positions, and (3) a multi-region mean-pooling mechanism to perform feature aggregation based on multiple window sizes. Experimental results on two real-world datasets demonstrate that our proposed model can detect fake news with greater than 90% accuracy within 5 minutes after it starts to spread and before it is retweeted 50 times, which is significantly faster than state-of-the-art baselines. Most importantly, our approach requires only 10% labeled fake news samples to achieve this effectiveness under PU-Learning settings.},
journal = {ACM Trans. Inf. Syst.},
month = may,
articleno = {25},
pages = {1–33},
numpages = {33},
keywords = {deep learning, Fake news detection, social media}
}
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{10.1145/2806416.2806652,
author = {Hassan, Naeemul and Li, Chengkai and Tremayne, Mark},
title = {Detecting Check-Worthy Factual Claims in Presidential Debates},
year = {2015},
isbn = {9781450337946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806416.2806652},
doi = {10.1145/2806416.2806652},
abstract = {Public figures such as politicians make claims about "facts" all the time. Journalists and citizens spend a good amount of time checking the veracity of such claims. Toward automatic fact checking, we developed tools to find check-worthy factual claims from natural language sentences. Specifically, we prepared a U.S. presidential debate dataset and built classification models to distinguish check-worthy factual claims from non-factual claims and unimportant factual claims. We also identified the most-effective features based on their impact on the classification models' accuracy.},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
pages = {1835–1838},
numpages = {4},
keywords = {text classification, computational journalism, fact checking},
location = {Melbourne, Australia},
series = {CIKM '15}
}
@inproceedings{vasileva-etal-2019-takes,
    title = "It Takes Nine to Smell a Rat: Neural Multi-Task Learning for Check-Worthiness Prediction",
    author = "Vasileva, Slavena  and
      Atanasova, Pepa  and
      M{\`a}rquez, Llu{\'\i}s  and
      Barr{\'o}n-Cede{\~n}o, Alberto  and
      Nakov, Preslav",
    booktitle = "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)",
    month = sep,
    year = "2019",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url = "https://www.aclweb.org/anthology/R19-1141",
    doi = "10.26615/978-954-452-056-4_141",
    pages = "1229--1239",
    abstract = "We propose a multi-task deep-learning approach for estimating the check-worthiness of claims in political debates. Given a political debate, such as the 2016 US Presidential and Vice-Presidential ones, the task is to predict which statements in the debate should be prioritized for fact-checking. While different fact-checking organizations would naturally make different choices when analyzing the same debate, we show that it pays to learn from multiple sources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post) in a multi-task learning setup, even when a particular source is chosen as a target to imitate. Our evaluation shows state-of-the-art results on a standard dataset for the task of check-worthiness prediction.",
}
@inproceedings{jaradat-etal-2018-claimrank,
    title = "{C}laim{R}ank: Detecting Check-Worthy Claims in {A}rabic and {E}nglish",
    author = "Jaradat, Israa  and
      Gencheva, Pepa  and
      Barr{\'o}n-Cede{\~n}o, Alberto  and
      M{\`a}rquez, Llu{\'\i}s  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-5006",
    doi = "10.18653/v1/N18-5006",
    pages = "26--30",
    abstract = "We present ClaimRank, an online system for detecting check-worthy claims. While originally trained on political debates, the system can work for any kind of text, e.g., interviews or just regular news articles. Its aim is to facilitate manual fact-checking efforts by prioritizing the claims that fact-checkers should consider first. ClaimRank supports both Arabic and English, it is trained on actual annotations from nine reputable fact-checking organizations (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post), and thus it can mimic the claim selection strategies for each and any of them, as well as for the union of them all.",
}
@InProceedings{10.1007/978-3-030-45442-5_65,
    author="Barr{\'o}n-Cede{\~{n}}o, Alberto
    and Elsayed, Tamer
    and Nakov, Preslav
    and Da San Martino, Giovanni
    and Hasanain, Maram
    and Suwaileh, Reem
    and Haouari, Fatima",
    editor="Jose, Joemon M.
    and Yilmaz, Emine
    and Magalh{\~a}es, Jo{\~a}o
    and Castells, Pablo
    and Ferro, Nicola
    and Silva, M{\'a}rio J.
    and Martins, Fl{\'a}vio",
    title="CheckThat! at CLEF 2020: Enabling the Automatic Identification and Verification of Claims in Social Media",
    booktitle="Advances in Information Retrieval",
    year="2020",
    publisher="Springer International Publishing",
    address="Cham",
    pages="499--507",
    abstract="We describe the third edition of the CheckThat! Lab, which is part of the 2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four complementary tasks and a related task from previous lab editions, offered in English, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter stream are worth fact-checking. Task 2 asks to determine whether a claim posted in a tweet can be verified using a set of previously fact-checked claims. Task 3 asks to retrieve text snippets from a given set of Web pages that would be useful for verifying a target tweet's claim. Task 4 asks to predict the veracity of a target tweet's claim using a set of potentially-relevant Web pages. Finally, the lab offers a fifth task that asks to predict the check-worthiness of the claims made in English political debates and speeches. CheckThat! features a full evaluation framework. The evaluation is carried out using mean average precision or precision at rank k for ranking tasks, and F{\$}{\$}{\_}1{\$}{\$} for classification tasks.",
    isbn="978-3-030-45442-5"
}
@inproceedings{shaar-etal-2020-known,
    title = "That is a Known Lie: Detecting Previously Fact-Checked Claims",
    author = "Shaar, Shaden  and
      Babulkov, Nikolay  and
      Da San Martino, Giovanni  and
      Nakov, Preslav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.332",
    doi = "10.18653/v1/2020.acl-main.332",
    pages = "3607--3618",
    abstract = "The recent proliferation of {''}fake news{''} has triggered a number of responses, most notably the emergence of several manual fact-checking initiatives. As a result and over time, a large number of fact-checked claims have been accumulated, which increases the likelihood that a new claim in social media or a new statement by a politician might have already been fact-checked by some trusted fact-checking organization, as viral claims often come back after a while in social media, and politicians like to repeat their favorite statements, true or false, over and over again. As manual fact-checking is very time-consuming (and fully automatic fact-checking has credibility issues), it is important to try to save this effort and to avoid wasting time on claims that have already been fact-checked. Interestingly, despite the importance of the task, it has been largely ignored by the research community so far. Here, we aim to bridge this gap. In particular, we formulate the task and we discuss how it relates to, but also differs from, previous work. We further create a specialized dataset, which we release to the research community. Finally, we present learning-to-rank experiments that demonstrate sizable improvements over state-of-the-art retrieval and textual similarity approaches.",
}
@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
    abstract = "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.",
}
@inproceedings{zhong-etal-2020-reasoning,
    title = "Reasoning Over Semantic-Level Graph for Fact Checking",
    author = "Zhong, Wanjun  and
      Xu, Jingjing  and
      Tang, Duyu  and
      Xu, Zenan  and
      Duan, Nan  and
      Zhou, Ming  and
      Wang, Jiahai  and
      Yin, Jian",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.549",
    doi = "10.18653/v1/2020.acl-main.549",
    pages = "6170--6180",
    abstract = "Fact checking is a challenging task because verifying the truthfulness of a claim requires reasoning about multiple retrievable evidence. In this work, we present a method suitable for reasoning about the semantic-level structure of evidence. Unlike most previous works, which typically represent evidence sentences with either string concatenation or fusing the features of isolated evidence sentences, our approach operates on rich semantic structures of evidence obtained by semantic role labeling. We propose two mechanisms to exploit the structure of evidence while leveraging the advances of pre-trained models like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we first utilize the graph structure to re-define the relative distances of words, with the intuition that semantically related words should have short distances. Then, we adopt graph convolutional network and graph attention network to propagate and aggregate information from neighboring nodes on the graph. We evaluate our system on FEVER, a benchmark dataset for fact checking, and find that rich structural information is helpful and both our graph-based mechanisms improve the accuracy. Our model is the state-of-the-art system in terms of both official evaluation metrics, namely claim verification accuracy and FEVER score.",
}
@inproceedings{thorne-etal-2019-fever2,
    title = "The {FEVER}2.0 Shared Task",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Cocarascu, Oana  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-6601",
    doi = "10.18653/v1/D19-6601",
    pages = "1--6",
    abstract = "We present the results of the second Fact Extraction and VERification (FEVER2.0) Shared Task. The task challenged participants to both build systems to verify factoid claims using evidence retrieved from Wikipedia and to generate adversarial attacks against other participant{'}s systems. The shared task had three phases: \textit{building, breaking and fixing}. There were 8 systems in the builder{'}s round, three of which were new qualifying submissions for this shared task, and 5 adversaries generated instances designed to induce classification errors and one builder submitted a fixed system which had higher FEVER score and resilience than their first submission. All but one newly submitted systems attained FEVER scores higher than the best performing system from the first shared task and under adversarial evaluation, all systems exhibited losses in FEVER score. There was a great variety in adversarial attack types as well as the techniques used to generate the attacks, In this paper, we present the results of the shared task and a summary of the systems, highlighting commonalities and innovations among participating systems.",
}
@misc{chen2020tabfact,
      title={TabFact: A Large-scale Dataset for Table-based Fact Verification}, 
      author={Wenhu Chen and Hongmin Wang and Jianshu Chen and Yunkai Zhang and Hong Wang and Shiyang Li and Xiyou Zhou and William Yang Wang},
      year={2020},
      eprint={1909.02164},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{10.14778/3407790.3407841,
author = {Karagiannis, Georgios and Saeed, Mohammed and Papotti, Paolo and Trummer, Immanuel},
title = {Scrutinizer: A Mixed-Initiative Approach to Large-Scale, Data-Driven Claim Verification},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3407790.3407841},
doi = {10.14778/3407790.3407841},
abstract = {Organizations spend significant amounts of time and money to manually fact check text documents summarizing data. The goal of the Scrutinizer system is to reduce verification overheads by supporting human fact checkers in translating text claims into SQL queries on an database. Scrutinizer coordinates teams of human fact checkers. It reduces verification time by proposing queries or query fragments to the users. Those proposals are based on claim text classifiers, that gradually improve during the verification of a large document. In addition, Scrutinizer uses tentative execution of query candidates to narrow down the set of alternatives. The verification process is controlled by a cost-based optimizer. It optimizes the interaction with users and prioritizes claim verifications. For the latter, it considers expected verification overheads as well as the expected claim utility as training samples for the classifiers. We evaluate the Scrutinizer system using simulations and a user study with professional fact checkers, based on actual claims and data. Our experiments consistently demonstrate significant savings in verification time, without reducing result accuracy.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {2508–2521},
numpages = {14}
}
@inproceedings{10.1145/3308558.3314126,
author = {Gad-Elrab, Mohamed H. and Stepanova, Daria and Urbani, Jacopo and Weikum, Gerhard},
title = {Tracy: Tracing Facts over Knowledge Graphs and Text},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3314126},
doi = {10.1145/3308558.3314126},
abstract = {In order to accurately populate and curate Knowledge Graphs (KGs), it is important to distinguish ?s?p?o? facts that can be traced back to sources from facts that cannot be verified. Manually validating each fact is time-consuming. Prior work on automating this task relied on numerical confidence scores which might not be easily interpreted. To overcome this limitation, we present Tracy, a novel tool that generates human-comprehensible explanations for candidate facts. Our tool relies on background knowledge in the form of rules to rewrite the fact in question into other easier-to-spot facts. These rewritings are then used to reason over the candidate fact creating semantic traces that can aid KG curators. The goal of our demonstration is to illustrate the main features of our system and to show how the semantic traces can be computed over both text and knowledge graphs with a simple and intuitive user interface. },
booktitle = {The World Wide Web Conference},
pages = {3516–3520},
numpages = {5},
keywords = {Knowledge Graph, Fact-checking, Reasoning, Explainable Evidence},
location = {San Francisco, CA, USA},
series = {WWW '19}
}
@misc{lee2020misinformation,
      title={Misinformation Has High Perplexity}, 
      author={Nayeon Lee and Yejin Bang and Andrea Madotto and Pascale Fung},
      year={2020},
      eprint={2006.04666},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{10.1145/1963405.1963500,
author = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
title = {Information Credibility on Twitter},
year = {2011},
isbn = {9781450306324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1963405.1963500},
doi = {10.1145/1963405.1963500},
abstract = {We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally.On this paper we focus on automatic methods for assessing the credibility of a given set of tweets. Specifically, we analyze microblog postings related to "trending" topics, and classify them as credible or not credible, based on features extracted from them. We use features from users' posting and re-posting ("re-tweeting") behavior, from the text of the posts, and from citations to external sources.We evaluate our methods using a significant number of human assessments about the credibility of items on a recent sample of Twitter postings. Our results shows that there are measurable differences in the way messages propagate, that can be used to classify them automatically as credible or not credible, with precision and recall in the range of 70% to 80%.},
booktitle = {Proceedings of the 20th International Conference on World Wide Web},
pages = {675–684},
numpages = {10},
keywords = {twitter, social media credibility, social media analytics},
location = {Hyderabad, India},
series = {WWW '11}
}
@inproceedings{10.5555/3061053.3061153,
author = {Ma, Jing and Gao, Wei and Mitra, Prasenjit and Kwon, Sejeong and Jansen, Bernard J. and Wong, Kam-Fai and Cha, Meeyoung},
title = {Detecting Rumors from Microblogs with Recurrent Neural Networks},
year = {2016},
isbn = {9781577357704},
publisher = {AAAI Press},
abstract = {Microblogging platforms are an ideal place for spreading rumors and automatically debunking rumors is a crucial problem. To detect rumors, existing approaches have relied on hand-crafted features for employing machine learning algorithms that require daunting manual effort. Upon facing a dubious claim, people dispute its truthfulness by posting various cues over time, which generates long-distance dependencies of evidence. This paper presents a novel method that learns continuous representations of microblog events for identifying rumors. The proposed model is based on recurrent neural networks (RNN) for learning the hidden representations that capture the variation of contextual information of relevant posts over time. Experimental results on datasets from two real-world microblog platforms demonstrate that (1) the RNN method outperforms state-of-the-art rumor detection models that use hand-crafted features; (2) performance of the RNN-based algorithm is further improved via sophisticated recurrent units and extra hidden layers; (3) RNN-based method detects rumors more quickly and accurately than existing techniques, including the leading online rumor debunking services.},
booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence},
pages = {3818–3824},
numpages = {7},
location = {New York, New York, USA},
series = {IJCAI'16}
}
@inproceedings{derczynski-etal-2017-semeval,
    title = "{S}em{E}val-2017 Task 8: {R}umour{E}val: Determining rumour veracity and support for rumours",
    author = "Derczynski, Leon  and
      Bontcheva, Kalina  and
      Liakata, Maria  and
      Procter, Rob  and
      Wong Sak Hoi, Geraldine  and
      Zubiaga, Arkaitz",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S17-2006",
    doi = "10.18653/v1/S17-2006",
    pages = "69--76",
    abstract = "Media is full of false claims. Even Oxford Dictionaries named {``}post-truth{''} as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. RumourEval is a SemEval shared task that aims to identify and handle rumours and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics {--} each having their own families of claims and replies {--} and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.",
}
@inproceedings{gorrell-etal-2019-semeval,
    title = "{S}em{E}val-2019 Task 7: {R}umour{E}val, Determining Rumour Veracity and Support for Rumours",
    author = "Gorrell, Genevieve  and
      Kochkina, Elena  and
      Liakata, Maria  and
      Aker, Ahmet  and
      Zubiaga, Arkaitz  and
      Bontcheva, Kalina  and
      Derczynski, Leon",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S19-2147",
    doi = "10.18653/v1/S19-2147",
    pages = "845--854",
    abstract = "Since the first RumourEval shared task in 2017, interest in automated claim validation has greatly increased, as the danger of {``}fake news{''} has become a mainstream concern. However automated support for rumour verification remains in its infancy. It is therefore important that a shared task in this area continues to provide a focus for effort, which is likely to increase. Rumour verification is characterised by the need to consider evolving conversations and news updates to reach a verdict on a rumour{'}s veracity. As in RumourEval 2017 we provided a dataset of dubious posts and ensuing conversations in social media, annotated both for stance and veracity. The social media rumours stem from a variety of breaking news stories and the dataset is expanded to include Reddit as well as new Twitter posts. There were two concrete tasks; rumour stance prediction and rumour verification, which we present in detail along with results achieved by participants. We received 22 system submissions (a 70{\%} increase from RumourEval 2017) many of which used state-of-the-art methodology to tackle the challenges involved.",
}
@inproceedings{tan-etal-2020-detecting,
    title = "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News",
    author = "Tan, Reuben  and
      Plummer, Bryan  and
      Saenko, Kate",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.163",
    doi = "10.18653/v1/2020.emnlp-main.163",
    pages = "2081--2106",
    abstract = "Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset which is comprised of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. Coupled with providing a relatively effective approach based on detecting visual-semantic inconsistencies, the valuable insights gleaned from our user study experiments and, consequently, this paper will serve as an effective first line of defense and a valuable reference for future work in defending against machine-generated disinformation.",
}
@misc{solaiman_clark_brundage_2020,
    title={GPT-2: 1.5B Release},
    howpublished = {\url{https://openai.com/blog/gpt-2-1-5b-release/}},
    journal={OpenAI},
    publisher={OpenAI},
    author={Solaiman, Irene and Clark, Jack and Brundage, Miles},
    year={2020},
    month={Sep},
    note={visited on 2021-01-26}
}
@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {5998--6008},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}
@misc{calvario_2017, 
    title={Eddie Cibrian Fires Back at Brandi Glanville After LeAnn Rimes Accusations: 'Not Healthy Behavior'},
    howpublished={\url{https://www.etonline.com/news/219403_eddie_cibrian_fires_back_at_brandi_glanville_after_leann_rimes_accusations_not_healthy_behavior}},
    journal={Entertainment Tonight},
    publisher={Entertainment Tonight},
    author={Calvario, Liz},
    year={2017},
    month={Jun},
    note={visited on 2021-01-26}
}
@online{bahou_2018, 
    title={Meghan Markle and Kate Middleton Relationship Details}, 
    howpublished = {\url{https://www.instyle.com/news/meghan-markle-kate-middleton-relationship}}, 
    journal={InStyle}, 
    author={Bahou, Olivia}, 
    year={2018}, 
    month={Mar},
    note={visited on 2021-01-26}
}
@misc{merriam-webster, 
    title={How Is 'Fake News' Defined, and When Will It Be Added to the Dictionary?},
    howpublished={\url{https://www.merriam-webster.com/words-at-play/the-real-story-of-fake-news}},
    journal={Merriam-Webster},
    publisher={Merriam-Webster},
    note={visited on 2021-01-26}
}
@article{内山香2018,
  title={ファクトチェックのための要検証記事探索の支援},
  author={内山 香 and 鈴木 海渡 and 田上 翼 and 塙 一晃 and 乾 健太郎 and 小宮 篤史 and 藤村 厚夫 and 町野 明徳 and 楊井 人文 and 山下 亮},
  journal={人工知能学会全国大会論文集},
  volume={JSAI2018},
  number={ },
  pages={4Pin126-4Pin126},
  year={2018},
  doi={10.11517/pjsai.JSAI2018.0_4Pin126}
}
@misc{collins_fake,
    title={Fake news definition and meaning: Collins English Dictionary},
    howpublished={\url{https://www.collinsdictionary.com/dictionary/english/fake-news}},
    journal={Fake news definition and meaning, Collins English Dictionary},
    publisher={HarperCollins Publishers Ltd},
    note={visited on 2021-02-01}
}
@misc{collins_word,
    title={Collins 2017 Word of the Year Shortlist},
    howpublished={\url{https://blog.collinsdictionary.com/language-lovers/collins-2017-word-of-the-year-shortlist/}},
    journal={Collins Dictionary Language Blog},
    year={2020},
    month={Nov},
    note={visited on 2021-02-02}
}
@article{wardle2017information,
  title={Information disorder: Toward an interdisciplinary framework for research and policy making},
  author={Wardle, Claire and Derakhshan, Hossein},
  journal={Council of Europe report},
  volume={27},
  pages={1--107},
  year={2017}
}
@misc{grice_2017,
    title={Fake news handed Brexiteers the referendum – and now they have no idea what they're doing},
    howpublished={\url{https://www.independent.co.uk/voices/michael-gove-boris-johnson-brexit-eurosceptic-press-theresa-may-a7533806.html}},
    journal={The Independent},
    publisher={Independent Digital News and Media},
    author={Grice, Andrew},
    year={2017},
    month={Jan},
    note={visited on 2021-02-02}
}
@misc{burleigh_2017,
    title={Big Brother is watching: How Big Data mines personal info to craft fake news, manipulate voters},
    howpublished={\url{https://www.newsweek.com/2017/06/16/big-data-mines-personal-info-manipulate-voters-623131.html}},
    journal={Newsweek},
    author={Burleigh, Nina},
    year={2017},
    month={Jun},
    note={visited on 2021-02-02}
}
@misc{merrick_2018,
    title={Brexit director who created £350m NHS claim admits leaving EU could be 'an error'},
    howpublished={\url{https://www.independent.co.uk/news/uk/politics/brexit-latest-news-vote-leave-director-dominic-cummings-leave-eu-error-nhs-ps350-million-lie-bus-advert-a7822386.html}},
    journal={The Independent},
    publisher={Independent Digital News and Media},
    author={Merrick, Rob},
    year={2018},
    month={Mar},
    note={visited on 2021-02-02}
}
@misc{reklaitis_2018,
    title={Web creator Tim Berners-Lee blasts Facebook, saying it makes his invention easy to 'weaponize'},
    howpublished={\url{https://www.marketwatch.com/story/webs-creator-blasts-the-tech-giants-that-make-his-invention-easy-to-weaponize-2018-03-12}},
    journal={MarketWatch},
    publisher={MarketWatch},
    author={Reklaitis, Victor},
    year={2018},
    month={Mar},
    note={visited on 2021-02-02}
}
@misc{wendling_2021,
    title={QAnon: What is it and where did it come from?},
    howpublished={\url{https://www.bbc.com/news/53498434}},
    journal={BBC News},
    publisher={BBC},
    author={Wendling, Mike},
    year={2021},
    month={Jan},
    note={visited on 2021-02-02}
}
@misc{hymes_mcdonald_watson_2021,
    title={"Unprecedented" in FBI history: What we know about the Capitol riot arrests},
    howpublished={\url{https://www.cbsnews.com/news/capitol-riot-arrests-2021-01-29/?intcid=CNM-00-10abd1h}},
    journal={CBS News},
    publisher={CBS Interactive},
    author={Hymes, Clare and McDonald, Cassidy and Watson, Elenor},
    year={2021},
    month={Jan},
    note={visited on 2021-02-02}
}
@misc{fisher_2013,
    title={Syrian hackers claim AP hack that tipped stock market by \textdollar 136 billion. Is it terrorism?},
    howpublished={\url{https://www.washingtonpost.com/news/worldviews/wp/2013/04/23/syrian-hackers-claim-ap-hack-that-tipped-stock-market-by-136-billion-is-it-terrorism/}},
    journal={The Washington Post},
    publisher={WP Company},
    author={Fisher, Max},
    year={2013},
    month={Apr},
    note={visited on 2021-02-02}
}
@misc{wardle_2017,
    title={Fake news. It's complicated.},
    howpublished={\url{https://firstdraftnews.org/latest/fake-news-complicated/}},
    journal={First Draft},
    author={Wardle, Claire},
    year={2017},
    month={May},
    note={visited on 2021-02-02}
}
@misc{frayer_2018,
    title={Viral WhatsApp Messages Are Triggering Mob Killings In India},
    howpublished={\url{https://www.npr.org/2018/07/18/629731693/fake-news-turns-deadly-in-india}},
    journal={NPR},
    publisher={NPR},
    author={Frayer, Lauren},
    year={2018},
    month={Jul},
    note={visited on 2021-02-02}
}
@misc{hao_2020,
    title={The coronavirus is the first true social-media "infodemic"},
    howpublished={\url{https://www.technologyreview.com/2020/02/12/844851/the-coronavirus-is-the-first-true-social-media-infodemic/}},
    journal={MIT Technology Review},
    publisher={MIT Technology Review},
    author={Hao, Karen},
    year={2020},
    month={May},
    note={visited on 2021-02-02}
}
@misc{euvsdisinfo_2020,
    title={EUvsDisinfo: disinformation operations about COVID-19 - European Union Open Data Portal},
    howpublished={\url{https://data.europa.eu/euodp/en/data/dataset/euvsdisinfo-disinformation-operations-about-covid-19}},
    journal={EU Open Data Portal},
    publisher={European External Action Service},
    author={EUvsDiSiNFO},
    year={2020},
    month={Apr},
    note={visited on 2021-02-02}
}
@misc{euvsdisinfo_2020_2,
    title={Figure of the Week: 8000},
    howpublished={\url{https://euvsdisinfo.eu/figure-of-the-week-8000-2/?highlight=8000}},
    author={EUvsDiSiNFO},
    journal={EU vs DISINFORMATION},
    year={2020},
    month={Apr},
    note={visited on 2021-02-02}
}
@misc{IFCN,
    title={The commitments of the code of principles},
    howpublished={\url{https://ifcncodeofprinciples.poynter.org/know-more/the-commitments-of-the-code-of-principles}},
    journal={IFCN Code of Principles},
    author={International Fact-Checking Network},
    note={visited on 2021-02-02}
}
@misc{fij,
    title={国際的なルール},
    howpublished={\url{https://fij.info/introduction/principles}},
    author={FIJ｜ファクトチェック・イニシアティブ},
    note={visited on 2021-02-02}
}
@misc{deahl_2019,
    title={Fact Checker Job Description: Salary, Skills, \& More},
    howpublished={\url{https://www.thebalancecareers.com/fact-checker-2316052}},
    journal={The Balance Careers},
    author={Deahl, Rachel},
    year={2019},
    month={May},
    note={visited on 2021-02-02}
}
@misc{stencel_luther_2020,
    title={Fact-checking count tops 300 for the first time},
    howpublished={\url{https://reporterslab.org/category/fact-checking/#article-2781}},
    journal={Duke Reporters' Lab},
    publisher={Duke University Sanford School of Public Policy},
    author={Stencel, Mark and Luther, Joel},
    year={2020},
    month={Oct},
    note={visited on 2021-02-02}
}
@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya}
}